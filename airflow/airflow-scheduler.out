[2m2026-01-05T19:14:19.600794Z[0m [[32m[1minfo     [0m] [1mStarting the scheduler        [0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:1055[0m
[2m2026-01-05T19:14:19.718137Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T19:14:19.727712Z[0m [[32m[1minfo     [0m] [1mMarked 1 SchedulerJob instances as failed[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2334[0m
[2m2026-01-05T19:19:19.764642Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 19:20:02.024942+00:00 version: 1
[2m2026-01-05T19:20:02.450511Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T19:20:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T19:20:02.450718Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T19:20:02.451276Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T19:20:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T19:20:02.452580Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T19:20:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T19:20:02.629519Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T19:20:08.002510Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m5.376692605990684[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b8f9a-22f0-7185-950a-d8d2097cb651[0m
[2m2026-01-05T19:20:08.137113Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 19:20:00+00:00: scheduled__2026-01-05T19:20:00+00:00, state:running, queued_at: 2026-01-05 19:20:02.024942+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 19:20:02.262165+00:00 end:2026-01-05 19:20:08.137269+00:00
[2m2026-01-05T19:20:08.137366Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 19:20:00+00:00, run_id=scheduled__2026-01-05T19:20:00+00:00, run_start_date=2026-01-05 19:20:02.262165+00:00, run_end_date=2026-01-05 19:20:08.137269+00:00, run_duration=5.875104, state=success, run_type=scheduled, data_interval_start=2026-01-05 19:20:00+00:00, data_interval_end=2026-01-05 19:20:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T19:20:08.158435Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T19:20:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T19:20:08.171080Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T19:20:00+00:00, map_index=-1, run_start_date=2026-01-05 19:20:02.638044+00:00, run_end_date=2026-01-05 19:20:07.651696+00:00, run_duration=10.014, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 19:20:02.451588+00:00, scheduled_dttm=2026-01-05 19:20:02.313741+00:00,queued_by_job_id=22, pid=159238[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T19:24:19.786393Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T19:29:19.807521Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 19:30:01.670707+00:00 version: 1
[2m2026-01-05T19:30:01.875353Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T19:30:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T19:30:01.875549Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T19:30:01.875664Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T19:30:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T19:30:01.876543Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T19:30:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T19:30:01.990815Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T19:30:07.085091Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 19:30:00+00:00: scheduled__2026-01-05T19:30:00+00:00, state:running, queued_at: 2026-01-05 19:30:01.670707+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 19:30:01.771041+00:00 end:2026-01-05 19:30:07.085253+00:00
[2m2026-01-05T19:30:07.085356Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 19:30:00+00:00, run_id=scheduled__2026-01-05T19:30:00+00:00, run_start_date=2026-01-05 19:30:01.771041+00:00, run_end_date=2026-01-05 19:30:07.085253+00:00, run_duration=5.314212, state=success, run_type=scheduled, data_interval_start=2026-01-05 19:30:00+00:00, data_interval_end=2026-01-05 19:30:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T19:30:07.127205Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m5.140799321990926[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b8fa3-494a-7447-b36d-1383e0f4513d[0m
[2m2026-01-05T19:30:08.241684Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T19:30:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T19:30:08.247280Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T19:30:00+00:00, map_index=-1, run_start_date=2026-01-05 19:30:02.001866+00:00, run_end_date=2026-01-05 19:30:06.811762+00:00, run_duration=8.809999999999999, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 19:30:01.875939+00:00, scheduled_dttm=2026-01-05 19:30:01.788982+00:00,queued_by_job_id=22, pid=159267[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T19:34:19.828716Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T19:39:19.849982Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 19:40:01.142840+00:00 version: 1
[2m2026-01-05T19:40:01.551014Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T19:40:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T19:40:01.551197Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T19:40:01.551297Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T19:40:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T19:40:01.553268Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T19:40:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T19:40:01.748718Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T19:40:07.070219Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m5.325632134015905[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b8fac-6ef9-7a93-9a75-d375f52e3d92[0m
[2m2026-01-05T19:40:07.302405Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 19:40:00+00:00: scheduled__2026-01-05T19:40:00+00:00, state:running, queued_at: 2026-01-05 19:40:01.142840+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 19:40:01.277338+00:00 end:2026-01-05 19:40:07.302556+00:00
[2m2026-01-05T19:40:07.302655Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 19:40:00+00:00, run_id=scheduled__2026-01-05T19:40:00+00:00, run_start_date=2026-01-05 19:40:01.277338+00:00, run_end_date=2026-01-05 19:40:07.302556+00:00, run_duration=6.025218, state=success, run_type=scheduled, data_interval_start=2026-01-05 19:40:00+00:00, data_interval_end=2026-01-05 19:40:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T19:40:07.464065Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T19:40:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T19:40:07.469344Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T19:40:00+00:00, map_index=-1, run_start_date=2026-01-05 19:40:01.757002+00:00, run_end_date=2026-01-05 19:40:06.803130+00:00, run_duration=10.046, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 19:40:01.551570+00:00, scheduled_dttm=2026-01-05 19:40:01.397275+00:00,queued_by_job_id=22, pid=159293[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T19:44:19.766754Z[0m [[32m[1minfo     [0m] [1mDAG bundles loaded: dags-folder, example_dags[0m [[0m[1m[34mairflow.dag_processing.bundles.manager.DagBundlesManager[0m][0m [36mloc[0m=[35mmanager.py:179[0m
[2m2026-01-05T19:44:19.870617Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T19:49:19.895736Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 19:50:01.576258+00:00 version: 1
[2m2026-01-05T19:50:01.817110Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T19:50:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T19:50:01.817321Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T19:50:01.817431Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T19:50:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T19:50:01.818370Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T19:50:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T19:50:01.908082Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T19:50:06.970723Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m5.066556759993546[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b8fb5-986c-7a39-b2ef-3abcfd6d961b[0m
[2m2026-01-05T19:50:07.601471Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 19:50:00+00:00: scheduled__2026-01-05T19:50:00+00:00, state:running, queued_at: 2026-01-05 19:50:01.576258+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 19:50:01.635872+00:00 end:2026-01-05 19:50:07.601642+00:00
[2m2026-01-05T19:50:07.601738Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 19:50:00+00:00, run_id=scheduled__2026-01-05T19:50:00+00:00, run_start_date=2026-01-05 19:50:01.635872+00:00, run_end_date=2026-01-05 19:50:07.601642+00:00, run_duration=5.96577, state=success, run_type=scheduled, data_interval_start=2026-01-05 19:50:00+00:00, data_interval_end=2026-01-05 19:50:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T19:50:07.655623Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T19:50:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T19:50:07.661062Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T19:50:00+00:00, map_index=-1, run_start_date=2026-01-05 19:50:01.917018+00:00, run_end_date=2026-01-05 19:50:06.784079+00:00, run_duration=9.867, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 19:50:01.817739+00:00, scheduled_dttm=2026-01-05 19:50:01.668854+00:00,queued_by_job_id=22, pid=159336[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T19:54:19.921892Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T19:59:19.945029Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 20:00:01.283195+00:00 version: 1
[2m2026-01-05T20:00:01.509038Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:00:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T20:00:01.509294Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T20:00:01.509398Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:00:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T20:00:01.510526Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:00:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T20:00:01.625416Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T20:00:06.466147Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m4.8451349179958925[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b8fbe-bf07-782a-814a-7928ff7507e7[0m
[2m2026-01-05T20:00:06.991072Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 20:00:00+00:00: scheduled__2026-01-05T20:00:00+00:00, state:running, queued_at: 2026-01-05 20:00:01.283195+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 20:00:01.407775+00:00 end:2026-01-05 20:00:06.991351+00:00
[2m2026-01-05T20:00:06.991491Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 20:00:00+00:00, run_id=scheduled__2026-01-05T20:00:00+00:00, run_start_date=2026-01-05 20:00:01.407775+00:00, run_end_date=2026-01-05 20:00:06.991351+00:00, run_duration=5.583576, state=success, run_type=scheduled, data_interval_start=2026-01-05 20:00:00+00:00, data_interval_end=2026-01-05 20:00:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T20:00:07.020896Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T20:00:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T20:00:07.026350Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T20:00:00+00:00, map_index=-1, run_start_date=2026-01-05 20:00:01.636150+00:00, run_end_date=2026-01-05 20:00:06.324071+00:00, run_duration=9.687999999999999, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 20:00:01.509782+00:00, scheduled_dttm=2026-01-05 20:00:01.427389+00:00,queued_by_job_id=22, pid=160021[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T20:04:20.111593Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T20:09:20.134765Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 20:10:01.071431+00:00 version: 1
[2m2026-01-05T20:10:01.199088Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:10:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T20:10:01.199277Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T20:10:01.199374Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:10:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T20:10:01.200265Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:10:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T20:10:01.257823Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T20:10:05.925891Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m4.671992667979794[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b8fc7-e5f2-7bb5-a859-1566c4f12fbd[0m
[2m2026-01-05T20:10:06.451838Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 20:10:00+00:00: scheduled__2026-01-05T20:10:00+00:00, state:running, queued_at: 2026-01-05 20:10:01.071431+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 20:10:01.124026+00:00 end:2026-01-05 20:10:06.452006+00:00
[2m2026-01-05T20:10:06.452098Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 20:10:00+00:00, run_id=scheduled__2026-01-05T20:10:00+00:00, run_start_date=2026-01-05 20:10:01.124026+00:00, run_end_date=2026-01-05 20:10:06.452006+00:00, run_duration=5.32798, state=success, run_type=scheduled, data_interval_start=2026-01-05 20:10:00+00:00, data_interval_end=2026-01-05 20:10:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T20:10:07.106723Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T20:10:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T20:10:07.112044Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T20:10:00+00:00, map_index=-1, run_start_date=2026-01-05 20:10:01.267384+00:00, run_end_date=2026-01-05 20:10:05.640228+00:00, run_duration=8.373000000000001, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 20:10:01.199657+00:00, scheduled_dttm=2026-01-05 20:10:01.173609+00:00,queued_by_job_id=22, pid=160173[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T20:14:19.786217Z[0m [[32m[1minfo     [0m] [1mDAG bundles loaded: dags-folder, example_dags[0m [[0m[1m[34mairflow.dag_processing.bundles.manager.DagBundlesManager[0m][0m [36mloc[0m=[35mmanager.py:179[0m
[2m2026-01-05T20:14:20.156169Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T20:19:20.177014Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 20:20:01.221617+00:00 version: 1
[2m2026-01-05T20:20:01.365702Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:20:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T20:20:01.365871Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T20:20:01.365961Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:20:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T20:20:01.366808Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:20:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T20:20:01.531712Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T20:20:06.229132Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m4.701112087990623[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b8fd1-0e49-7dd3-aefd-6dcc4c94b5af[0m
[2m2026-01-05T20:20:06.705901Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 20:20:00+00:00: scheduled__2026-01-05T20:20:00+00:00, state:running, queued_at: 2026-01-05 20:20:01.221617+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 20:20:01.290760+00:00 end:2026-01-05 20:20:06.706042+00:00
[2m2026-01-05T20:20:06.706127Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 20:20:00+00:00, run_id=scheduled__2026-01-05T20:20:00+00:00, run_start_date=2026-01-05 20:20:01.290760+00:00, run_end_date=2026-01-05 20:20:06.706042+00:00, run_duration=5.415282, state=success, run_type=scheduled, data_interval_start=2026-01-05 20:20:00+00:00, data_interval_end=2026-01-05 20:20:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T20:20:06.726719Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T20:20:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T20:20:06.731754Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T20:20:00+00:00, map_index=-1, run_start_date=2026-01-05 20:20:01.541168+00:00, run_end_date=2026-01-05 20:20:06.027779+00:00, run_duration=9.487, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 20:20:01.366224+00:00, scheduled_dttm=2026-01-05 20:20:01.313288+00:00,queued_by_job_id=22, pid=160307[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T20:24:20.210881Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T20:29:20.230768Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 20:30:01.304247+00:00 version: 1
[2m2026-01-05T20:30:01.867252Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:30:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T20:30:01.867433Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T20:30:01.867526Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:30:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T20:30:01.868373Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:30:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T20:30:02.707795Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T20:30:10.529019Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 20:30:00+00:00: scheduled__2026-01-05T20:30:00+00:00, state:running, queued_at: 2026-01-05 20:30:01.304247+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 20:30:01.517289+00:00 end:2026-01-05 20:30:10.529155+00:00
[2m2026-01-05T20:30:10.529253Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 20:30:00+00:00, run_id=scheduled__2026-01-05T20:30:00+00:00, run_start_date=2026-01-05 20:30:01.517289+00:00, run_end_date=2026-01-05 20:30:10.529155+00:00, run_duration=9.011866, state=success, run_type=scheduled, data_interval_start=2026-01-05 20:30:00+00:00, data_interval_end=2026-01-05 20:30:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T20:30:10.818214Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m8.114037277002353[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b8fda-365b-7dd8-9fa3-4651c6aff7f6[0m
[2m2026-01-05T20:30:11.195164Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T20:30:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T20:30:11.200196Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T20:30:00+00:00, map_index=-1, run_start_date=2026-01-05 20:30:02.715782+00:00, run_end_date=2026-01-05 20:30:09.084121+00:00, run_duration=13.368, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 20:30:01.867808+00:00, scheduled_dttm=2026-01-05 20:30:01.643736+00:00,queued_by_job_id=22, pid=160435[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T20:34:20.255835Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T20:39:20.276351Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 20:40:01.976950+00:00 version: 1
[2m2026-01-05T20:40:02.033818Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:40:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T20:40:02.033978Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T20:40:02.034086Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:40:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T20:40:02.034894Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:40:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T20:40:02.103645Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T20:40:06.904378Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m4.804431597003713[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b8fe3-60bc-7d1d-b858-695dcd6aadf1[0m
[2m2026-01-05T20:40:06.936510Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 20:40:00+00:00: scheduled__2026-01-05T20:40:00+00:00, state:running, queued_at: 2026-01-05 20:40:01.976950+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 20:40:01.999336+00:00 end:2026-01-05 20:40:06.936669+00:00
[2m2026-01-05T20:40:06.936755Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 20:40:00+00:00, run_id=scheduled__2026-01-05T20:40:00+00:00, run_start_date=2026-01-05 20:40:01.999336+00:00, run_end_date=2026-01-05 20:40:06.936669+00:00, run_duration=4.937333, state=success, run_type=scheduled, data_interval_start=2026-01-05 20:40:00+00:00, data_interval_end=2026-01-05 20:40:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T20:40:06.956313Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T20:40:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T20:40:06.961790Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T20:40:00+00:00, map_index=-1, run_start_date=2026-01-05 20:40:02.111675+00:00, run_end_date=2026-01-05 20:40:06.634821+00:00, run_duration=8.523, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 20:40:02.034340+00:00, scheduled_dttm=2026-01-05 20:40:02.018649+00:00,queued_by_job_id=22, pid=160554[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T20:44:19.825611Z[0m [[32m[1minfo     [0m] [1mDAG bundles loaded: dags-folder, example_dags[0m [[0m[1m[34mairflow.dag_processing.bundles.manager.DagBundlesManager[0m][0m [36mloc[0m=[35mmanager.py:179[0m
[2m2026-01-05T20:44:20.298873Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T20:49:20.319965Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 20:50:01.460238+00:00 version: 1
[2m2026-01-05T20:50:02.258089Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:50:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T20:50:02.258258Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T20:50:02.258369Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:50:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T20:50:02.259224Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T20:50:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T20:50:02.418924Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T20:50:08.793471Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m6.378422200999921[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b8fec-8677-7646-bc6c-215234652dd6[0m
[2m2026-01-05T20:50:09.367855Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 20:50:00+00:00: scheduled__2026-01-05T20:50:00+00:00, state:running, queued_at: 2026-01-05 20:50:01.460238+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 20:50:01.767216+00:00 end:2026-01-05 20:50:09.367992+00:00
[2m2026-01-05T20:50:09.368075Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 20:50:00+00:00, run_id=scheduled__2026-01-05T20:50:00+00:00, run_start_date=2026-01-05 20:50:01.767216+00:00, run_end_date=2026-01-05 20:50:09.367992+00:00, run_duration=7.600776, state=success, run_type=scheduled, data_interval_start=2026-01-05 20:50:00+00:00, data_interval_end=2026-01-05 20:50:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T20:50:09.639330Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T20:50:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T20:50:09.644290Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T20:50:00+00:00, map_index=-1, run_start_date=2026-01-05 20:50:02.427207+00:00, run_end_date=2026-01-05 20:50:07.849746+00:00, run_duration=10.423, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 20:50:02.258641+00:00, scheduled_dttm=2026-01-05 20:50:02.071875+00:00,queued_by_job_id=22, pid=160674[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T20:54:20.341424Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T20:59:20.362147Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 21:00:01.649051+00:00 version: 1
[2m2026-01-05T21:00:02.476412Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:00:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T21:00:02.476586Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T21:00:02.476692Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:00:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T21:00:02.477534Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:00:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T21:00:02.585420Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T21:00:07.980409Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 21:00:00+00:00: scheduled__2026-01-05T21:00:00+00:00, state:running, queued_at: 2026-01-05 21:00:01.649051+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 21:00:02.416703+00:00 end:2026-01-05 21:00:07.980543+00:00
[2m2026-01-05T21:00:07.980627Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 21:00:00+00:00, run_id=scheduled__2026-01-05T21:00:00+00:00, run_start_date=2026-01-05 21:00:02.416703+00:00, run_end_date=2026-01-05 21:00:07.980543+00:00, run_duration=5.56384, state=success, run_type=scheduled, data_interval_start=2026-01-05 21:00:00+00:00, data_interval_end=2026-01-05 21:00:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T21:00:08.392689Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m5.810857308009872[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b8ff5-aef4-7fc6-b0a3-ae00e388d651[0m
[2m2026-01-05T21:00:08.620607Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T21:00:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T21:00:08.625757Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T21:00:00+00:00, map_index=-1, run_start_date=2026-01-05 21:00:02.593653+00:00, run_end_date=2026-01-05 21:00:07.763474+00:00, run_duration=10.169, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 21:00:02.476966+00:00, scheduled_dttm=2026-01-05 21:00:02.445521+00:00,queued_by_job_id=22, pid=160804[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T21:04:20.383302Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T21:09:20.404079Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 21:10:01.319696+00:00 version: 1
[2m2026-01-05T21:10:02.130127Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:10:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T21:10:02.130307Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T21:10:02.130401Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:10:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T21:10:02.131244Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:10:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T21:10:02.267468Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T21:10:14.188105Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 21:10:00+00:00: scheduled__2026-01-05T21:10:00+00:00, state:running, queued_at: 2026-01-05 21:10:01.319696+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 21:10:01.756675+00:00 end:2026-01-05 21:10:14.188251+00:00
[2m2026-01-05T21:10:14.188347Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 21:10:00+00:00, run_id=scheduled__2026-01-05T21:10:00+00:00, run_start_date=2026-01-05 21:10:01.756675+00:00, run_end_date=2026-01-05 21:10:14.188251+00:00, run_duration=12.431576, state=success, run_type=scheduled, data_interval_start=2026-01-05 21:10:00+00:00, data_interval_end=2026-01-05 21:10:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T21:10:14.597445Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m12.333978550013853[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b8ffe-d56b-7c11-a5f8-3244426445df[0m
[2m2026-01-05T21:10:15.436336Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T21:10:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T21:10:15.441498Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T21:10:00+00:00, map_index=-1, run_start_date=2026-01-05 21:10:02.275485+00:00, run_end_date=2026-01-05 21:10:11.411338+00:00, run_duration=18.136, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 21:10:02.130674+00:00, scheduled_dttm=2026-01-05 21:10:02.060108+00:00,queued_by_job_id=22, pid=160936[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T21:14:19.843695Z[0m [[32m[1minfo     [0m] [1mDAG bundles loaded: dags-folder, example_dags[0m [[0m[1m[34mairflow.dag_processing.bundles.manager.DagBundlesManager[0m][0m [36mloc[0m=[35mmanager.py:179[0m
[2m2026-01-05T21:14:20.573818Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T21:19:20.594614Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 21:20:01.523966+00:00 version: 1
[2m2026-01-05T21:20:01.908748Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:20:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T21:20:01.908927Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T21:20:01.909023Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:20:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T21:20:01.909873Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:20:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T21:20:01.958350Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T21:20:07.823551Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 21:20:00+00:00: scheduled__2026-01-05T21:20:00+00:00, state:running, queued_at: 2026-01-05 21:20:01.523966+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 21:20:01.885178+00:00 end:2026-01-05 21:20:07.823703+00:00
[2m2026-01-05T21:20:07.823791Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 21:20:00+00:00, run_id=scheduled__2026-01-05T21:20:00+00:00, run_start_date=2026-01-05 21:20:01.885178+00:00, run_end_date=2026-01-05 21:20:07.823703+00:00, run_duration=5.938525, state=success, run_type=scheduled, data_interval_start=2026-01-05 21:20:00+00:00, data_interval_end=2026-01-05 21:20:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T21:20:11.869656Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m9.914863301994046[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b9007-fdf6-79bd-a494-ac90d5f9052e[0m
[2m2026-01-05T21:20:12.299354Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T21:20:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T21:20:12.304305Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T21:20:00+00:00, map_index=-1, run_start_date=2026-01-05 21:20:01.966132+00:00, run_end_date=2026-01-05 21:20:06.768227+00:00, run_duration=9.802, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 21:20:01.909281+00:00, scheduled_dttm=2026-01-05 21:20:01.898651+00:00,queued_by_job_id=22, pid=161233[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T21:24:20.615495Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T21:29:20.636120Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 21:30:01.105487+00:00 version: 1
[2m2026-01-05T21:30:01.175311Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:30:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T21:30:01.175476Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T21:30:01.175575Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:30:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T21:30:01.176481Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:30:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T21:30:01.246288Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T21:30:06.110099Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m4.867629884014605[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b9011-2414-70d6-8bf1-c334aa21fd20[0m
[2m2026-01-05T21:30:06.255989Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 21:30:00+00:00: scheduled__2026-01-05T21:30:00+00:00, state:running, queued_at: 2026-01-05 21:30:01.105487+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 21:30:01.139983+00:00 end:2026-01-05 21:30:06.256121+00:00
[2m2026-01-05T21:30:06.256202Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 21:30:00+00:00, run_id=scheduled__2026-01-05T21:30:00+00:00, run_start_date=2026-01-05 21:30:01.139983+00:00, run_end_date=2026-01-05 21:30:06.256121+00:00, run_duration=5.116138, state=success, run_type=scheduled, data_interval_start=2026-01-05 21:30:00+00:00, data_interval_end=2026-01-05 21:30:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T21:30:06.273537Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T21:30:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T21:30:06.278494Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T21:30:00+00:00, map_index=-1, run_start_date=2026-01-05 21:30:01.254149+00:00, run_end_date=2026-01-05 21:30:05.821242+00:00, run_duration=8.567, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 21:30:01.175849+00:00, scheduled_dttm=2026-01-05 21:30:01.160387+00:00,queued_by_job_id=22, pid=161377[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 21:34:16.167041+00:00 version: 1
[2m2026-01-05T21:34:17.984461Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql manual__2026-01-05T21:34:05+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T21:34:17.984650Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T21:34:17.984756Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql manual__2026-01-05T21:34:05+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T21:34:17.985594Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql manual__2026-01-05T21:34:05+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T21:34:18.122430Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T21:34:20.833945Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T21:34:23.718908Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 21:34:05+00:00: manual__2026-01-05T21:34:05+00:00, state:running, queued_at: 2026-01-05 21:34:16.167041+00:00. run_type: manual> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 21:34:17.053475+00:00 end:2026-01-05 21:34:23.719075+00:00
[2m2026-01-05T21:34:23.719167Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 21:34:05+00:00, run_id=manual__2026-01-05T21:34:05+00:00, run_start_date=2026-01-05 21:34:17.053475+00:00, run_end_date=2026-01-05 21:34:23.719075+00:00, run_duration=6.6656, state=success, run_type=manual, data_interval_start=2026-01-05 21:34:05+00:00, data_interval_end=2026-01-05 21:34:05+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T21:34:27.939335Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m9.820432188978884[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b9015-086d-77a2-a195-e0a927077818[0m
[2m2026-01-05T21:34:28.517798Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='manual__2026-01-05T21:34:05+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T21:34:28.522831Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=manual__2026-01-05T21:34:05+00:00, map_index=-1, run_start_date=2026-01-05 21:34:18.130135+00:00, run_end_date=2026-01-05 21:34:22.741524+00:00, run_duration=8.612, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 21:34:17.985025+00:00, scheduled_dttm=2026-01-05 21:34:17.427290+00:00,queued_by_job_id=22, pid=161475[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T21:39:20.855404Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 21:40:01.021386+00:00 version: 1
[2m2026-01-05T21:40:01.081950Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:40:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T21:40:01.082108Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T21:40:01.082209Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:40:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T21:40:01.083053Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:40:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T21:40:01.138954Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T21:40:05.979803Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m4.84450880199438[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b901a-4b80-7ae8-a539-01ad08cddaae[0m
[2m2026-01-05T21:40:06.799504Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 21:40:00+00:00: scheduled__2026-01-05T21:40:00+00:00, state:running, queued_at: 2026-01-05 21:40:01.021386+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 21:40:01.048391+00:00 end:2026-01-05 21:40:06.799661+00:00
[2m2026-01-05T21:40:06.799747Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 21:40:00+00:00, run_id=scheduled__2026-01-05T21:40:00+00:00, run_start_date=2026-01-05 21:40:01.048391+00:00, run_end_date=2026-01-05 21:40:06.799661+00:00, run_duration=5.75127, state=success, run_type=scheduled, data_interval_start=2026-01-05 21:40:00+00:00, data_interval_end=2026-01-05 21:40:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T21:40:06.830664Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T21:40:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T21:40:06.836296Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T21:40:00+00:00, map_index=-1, run_start_date=2026-01-05 21:40:01.147238+00:00, run_end_date=2026-01-05 21:40:05.842312+00:00, run_duration=8.695, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 21:40:01.082476+00:00, scheduled_dttm=2026-01-05 21:40:01.066440+00:00,queued_by_job_id=22, pid=161519[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T21:44:19.873339Z[0m [[32m[1minfo     [0m] [1mDAG bundles loaded: dags-folder, example_dags[0m [[0m[1m[34mairflow.dag_processing.bundles.manager.DagBundlesManager[0m][0m [36mloc[0m=[35mmanager.py:179[0m
[2m2026-01-05T21:44:20.876444Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T21:49:20.898408Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 21:50:01.703110+00:00 version: 1
[2m2026-01-05T21:50:01.847343Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:50:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T21:50:01.847511Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T21:50:01.847605Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:50:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T21:50:01.848455Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T21:50:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T21:50:01.905364Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T21:50:07.440225Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m5.538458006980363[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b9023-75ea-7c60-8b05-ca101538a2cf[0m
[2m2026-01-05T21:50:07.477921Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T21:50:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T21:50:07.483180Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T21:50:00+00:00, map_index=-1, run_start_date=2026-01-05 21:50:01.913193+00:00, run_end_date=2026-01-05 21:50:06.906256+00:00, run_duration=9.993, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 21:50:01.847878+00:00, scheduled_dttm=2026-01-05 21:50:01.829983+00:00,queued_by_job_id=22, pid=161636[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T21:50:08.510692Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 21:50:00+00:00: scheduled__2026-01-05T21:50:00+00:00, state:running, queued_at: 2026-01-05 21:50:01.703110+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 21:50:01.787425+00:00 end:2026-01-05 21:50:08.510827+00:00
[2m2026-01-05T21:50:08.510912Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 21:50:00+00:00, run_id=scheduled__2026-01-05T21:50:00+00:00, run_start_date=2026-01-05 21:50:01.787425+00:00, run_end_date=2026-01-05 21:50:08.510827+00:00, run_duration=6.723402, state=success, run_type=scheduled, data_interval_start=2026-01-05 21:50:00+00:00, data_interval_end=2026-01-05 21:50:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T21:54:20.921125Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T21:59:20.942298Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 22:00:01.107733+00:00 version: 1
[2m2026-01-05T22:00:01.277840Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T22:00:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T22:00:01.278008Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T22:00:01.278104Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T22:00:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T22:00:01.278965Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T22:00:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T22:00:01.378265Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T22:00:06.169281Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m4.794833205000032[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b902c-9b57-7a02-9f71-a449ca11b788[0m
[2m2026-01-05T22:00:06.933285Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 22:00:00+00:00: scheduled__2026-01-05T22:00:00+00:00, state:running, queued_at: 2026-01-05 22:00:01.107733+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 22:00:01.173404+00:00 end:2026-01-05 22:00:06.933421+00:00
[2m2026-01-05T22:00:06.933507Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 22:00:00+00:00, run_id=scheduled__2026-01-05T22:00:00+00:00, run_start_date=2026-01-05 22:00:01.173404+00:00, run_end_date=2026-01-05 22:00:06.933421+00:00, run_duration=5.760017, state=success, run_type=scheduled, data_interval_start=2026-01-05 22:00:00+00:00, data_interval_end=2026-01-05 22:00:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T22:00:06.962927Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T22:00:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T22:00:06.968731Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T22:00:00+00:00, map_index=-1, run_start_date=2026-01-05 22:00:01.386565+00:00, run_end_date=2026-01-05 22:00:06.029044+00:00, run_duration=9.642, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 22:00:01.278384+00:00, scheduled_dttm=2026-01-05 22:00:01.255416+00:00,queued_by_job_id=22, pid=161761[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T22:04:20.963116Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T22:09:20.983916Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 22:10:01.522017+00:00 version: 1
[2m2026-01-05T22:10:01.586970Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T22:10:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T22:10:01.587127Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T22:10:01.587226Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T22:10:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T22:10:01.588066Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T22:10:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T22:10:01.642493Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T22:10:06.474105Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m4.835190490994137[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b9035-c4b5-7944-92ef-c02d987c6002[0m
[2m2026-01-05T22:10:06.817571Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 22:10:00+00:00: scheduled__2026-01-05T22:10:00+00:00, state:running, queued_at: 2026-01-05 22:10:01.522017+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 22:10:01.545127+00:00 end:2026-01-05 22:10:06.817726+00:00
[2m2026-01-05T22:10:06.817811Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 22:10:00+00:00, run_id=scheduled__2026-01-05T22:10:00+00:00, run_start_date=2026-01-05 22:10:01.545127+00:00, run_end_date=2026-01-05 22:10:06.817726+00:00, run_duration=5.272599, state=success, run_type=scheduled, data_interval_start=2026-01-05 22:10:00+00:00, data_interval_end=2026-01-05 22:10:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T22:10:06.835883Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T22:10:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T22:10:06.840911Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T22:10:00+00:00, map_index=-1, run_start_date=2026-01-05 22:10:01.650509+00:00, run_end_date=2026-01-05 22:10:06.355781+00:00, run_duration=9.705, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 22:10:01.587481+00:00, scheduled_dttm=2026-01-05 22:10:01.571946+00:00,queued_by_job_id=22, pid=161897[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T22:14:19.900679Z[0m [[32m[1minfo     [0m] [1mDAG bundles loaded: dags-folder, example_dags[0m [[0m[1m[34mairflow.dag_processing.bundles.manager.DagBundlesManager[0m][0m [36mloc[0m=[35mmanager.py:179[0m
[2m2026-01-05T22:14:21.007180Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
[2m2026-01-05T22:19:21.030409Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
Dag run  in running state
Dag information Queued at: 2026-01-05 22:20:01.539907+00:00 version: 1
[2m2026-01-05T22:20:01.629976Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T22:20:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:445[0m
[2m2026-01-05T22:20:01.630150Z[0m [[32m[1minfo     [0m] [1mDAG weather_deduplication has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:517[0m
[2m2026-01-05T22:20:01.630249Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T22:20:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:656[0m
[2m2026-01-05T22:20:01.631114Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: weather_deduplication.run_deduplication_sql scheduled__2026-01-05T22:20:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:741[0m
[2m2026-01-05T22:20:01.707370Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend', 'MetastoreBackend'][0m [36mcount[0m=[35m2[0m [36mloc[0m=[35msupervisor.py:1975[0m
[2m2026-01-05T22:20:06.196937Z[0m [[32m[1minfo     [0m] [1mTask finished                 [0m [[0m[1m[34msupervisor[0m][0m [36mduration[0m=[35m4.495534501998918[0m [36mexit_code[0m=[35m0[0m [36mfinal_state[0m=[35msuccess[0m [36mloc[0m=[35msupervisor.py:1995[0m [36mtask_instance_id[0m=[35m019b903e-ec86-743a-a98b-a65036ff660a[0m
[2m2026-01-05T22:20:07.066822Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun weather_deduplication @ 2026-01-05 22:20:00+00:00: scheduled__2026-01-05T22:20:00+00:00, state:running, queued_at: 2026-01-05 22:20:01.539907+00:00. run_type: scheduled> successful[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1204[0m
Dag run in success state
Dag run start:2026-01-05 22:20:01.577031+00:00 end:2026-01-05 22:20:07.066997+00:00
[2m2026-01-05T22:20:07.067099Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=weather_deduplication, logical_date=2026-01-05 22:20:00+00:00, run_id=scheduled__2026-01-05T22:20:00+00:00, run_start_date=2026-01-05 22:20:01.577031+00:00, run_end_date=2026-01-05 22:20:07.066997+00:00, run_duration=5.489966, state=success, run_type=scheduled, data_interval_start=2026-01-05 22:20:00+00:00, data_interval_end=2026-01-05 22:20:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2026-01-05T22:20:07.101245Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state success for task instance TaskInstanceKey(dag_id='weather_deduplication', task_id='run_deduplication_sql', run_id='scheduled__2026-01-05T22:20:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:819[0m
[2m2026-01-05T22:20:07.106803Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=weather_deduplication, task_id=run_deduplication_sql, run_id=scheduled__2026-01-05T22:20:00+00:00, map_index=-1, run_start_date=2026-01-05 22:20:01.718244+00:00, run_end_date=2026-01-05 22:20:06.086257+00:00, run_duration=9.368, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=1, operator=BigQueryInsertJobOperator, queued_dttm=2026-01-05 22:20:01.630510+00:00, scheduled_dttm=2026-01-05 22:20:01.612613+00:00,queued_by_job_id=22, pid=162346[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:865[0m
[2m2026-01-05T22:24:21.053413Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2311[0m
